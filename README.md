# Memento

**Persistent semantic memory for AI agents.** Local, fast, and privacy-focused.

> *Memento gives AI agents persistent, semantic memory that survives sessions, scales efficiently, and recalls what mattersâ€”without drowning in context.*

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Tests](https://img.shields.io/badge/tests-passing-brightgreen.svg)](./run_tests.sh)

## Why Memento?

- **ğŸ§  Token Efficient:** Semantic recall loads only relevant context, not full history
- **âš¡ Fast:** 274,000x speedup with LRU cache (9ms warm search)
- **ğŸª¶ Lightweight:** SQLite + NumPy, no cloud dependencies
- **ğŸ›¡ï¸ Resilient:** Survives crashes, auto-backup, auto-rollback
- **ğŸ¤ Team Ready:** Proper GitHub workflow, documented, contributor-friendly
- **ğŸ¦€ Rust Hybrid:** Rust embedding engine for sub-millisecond cold start (optional)

## Quick Start

```bash
# Install from source
git clone https://github.com/rollersrights/memento.git
cd memento
pip install -e .

# Or install dependencies directly
pip install -r requirements.txt

# Store a memory
memento remember "The server IP is 192.168.1.155" --tags "infra"

# Recall it
memento recall "where is the server?"
```

## The CLI

Memento detects if you're a human or a script.

**Human Mode (Rich Tables):**
```text
ID        Score   Text
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
a1b2c3d4  0.89    The server IP is...
```

**Script Mode (JSON):**
```bash
memento recall "server" | jq .[0].text
# "The server IP is 192.168.1.155"
```

## Python API

```python
from memento import get_store, Memory, SearchResult

# Get singleton store instance
store = get_store()

# Store a memory
doc_id = store.remember(
    text="Deploy new model to production",
    importance=0.9,
    tags=["todo", "deploy"],
    collection="tasks"
)

# Search memories
results = store.recall(
    query="deployment tasks",
    topk=5,
    filters={"tags": ["todo"]},
    timeout_ms=5000
)

for result in results:
    print(f"{result['score']:.3f}: {result['text']}")

# Batch search for multiple queries
batch_results = store.batch_recall(
    queries=["deployment", "meeting notes", "bug fixes"],
    topk=3
)
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query   â”‚â”€â”€â”€â–¶â”‚  RAM Cache  â”‚â”€â”€â”€â–¶â”‚  Disk Cache  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  (0.03ms)   â”‚    â”‚   (SQLite)   â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ (miss)           â”‚ (miss)
                â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”           â”‚
                â”‚ ONNX/PyTorchâ”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚  Inference  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Storage Backends

- **NumPy (default):** Pure Python, works everywhere
- **FAISS:** Optimized for 10,000+ vectors
- **HNSW:** Fastest approximate search

### Embedding Backends

- **ONNX Runtime:** Fast inference on AVX2 CPUs
- **PyTorch:** Compatible fallback
- **Rust (optional):** Sub-millisecond cold start

## Configuration

Environment variables:
```bash
export MEMORY_DB_PATH=/path/to/custom/memory.db
export MEMENTO_RUST=1  # Enable Rust engine (if available)
export MEMORY_ECHO=1   # Show storage confirmations
```

Config file (`~/.memento/config.yaml`):
```yaml
storage:
  db_path: ~/.memento/memory.db
  backup_enabled: true
  
embedding:
  model: all-MiniLM-L6-v2
  use_onnx: true
  
cache:
  lru_size: 1000
```

## Development

Run the test suite:
```bash
./run_tests.sh
```

Or with pytest:
```bash
pytest tests/ -v
```

Lint and format:
```bash
flake8 .
black .
```

## Project Structure

```
memento/
â”œâ”€â”€ memento/           # Main package
â”‚   â”œâ”€â”€ __init__.py    # Public API
â”‚   â”œâ”€â”€ store.py       # MemoryStore class
â”‚   â”œâ”€â”€ embed.py       # Embedding engine
â”‚   â”œâ”€â”€ search.py      # Vector search
â”‚   â”œâ”€â”€ cli.py         # Command line interface
â”‚   â”œâ”€â”€ models.py      # Data models (Memory, SearchResult)
â”‚   â”œâ”€â”€ exceptions.py  # Custom exceptions
â”‚   â”œâ”€â”€ config.py      # Configuration management
â”‚   â””â”€â”€ migrations.py  # Database migrations
â”œâ”€â”€ scripts/           # Legacy scripts (deprecated)
â”œâ”€â”€ tests/             # Test suite
â”œâ”€â”€ memento_rs/        # Rust implementation (optional)
â””â”€â”€ docs/              # Documentation
```

## Roadmap

- âœ… **v0.2.0:** LRU caching, persistent disk cache, CLI
- âœ… **v0.2.1:** Echo notifications, storage threshold tuning
- âœ… **v0.2.2:** Background model loading, query timeout, type hints
- ğŸ”„ **v0.3.0:** Rust embedding engine (Phase 2a of RFC-001)
- â³ **v0.4.0:** Rust vector search (Phase 2b)
- â³ **v1.0.0:** Full production release

## Contributing

See [CONTRIBUTING.md](./CONTRIBUTING.md) for development setup and guidelines.

We use GitHub Issues â†’ Branches â†’ PRs â†’ Reviews â†’ Merge workflow.

## License

MIT

---

*Memento: Because AI shouldn't forget.*
